{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle winners.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanalvarez96/KAGGLE_DATASCIENCE/blob/master/Kaggle_winners.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx0fzCJ_4W0J",
        "colab_type": "code",
        "outputId": "f4d0164e-3989-447c-d77a-574fec3a4c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Libraries\n",
        "%matplotlib inline\n",
        "#PyTorch, of course\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "#We will need torchvision transforms for data augmentation\n",
        "\n",
        "import torchvision.models as models\n",
        "### utilities\n",
        "# tool to print a nice summary of a network, similary to keras' summary\n",
        "from torchsummary import summary\n",
        "\n",
        "# library to do bash-like wildcard expansion\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# others\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm_notebook\n",
        "from torchvision import datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_path = \"/content/drive/My Drive/polytech-ds-2019/polytech-ds-2019/training\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg5Bu0AMs55r",
        "colab_type": "text"
      },
      "source": [
        "# **Import Data and generate DataLoaders**\n",
        "This process will be carried out using tbe torchvisison datasets set of function for importing data.\\\n",
        "Since the provided data is shuffled, we will organize each picture in folders. This implies, for every image from the training and validation folders, we will move it to a class folder.\n",
        "\n",
        "\n",
        "1.   Create for the validation folder 10 folders following the structure: class0, class1, ..., class10\n",
        "2.   Move every image from validation folder to its respective class folder. Move 01_xyz.jpg to class1, move 02_xyz.jpg to class2, ...\n",
        "3. Repeat these two steps fro the training floder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUhQaLTYzpGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformations=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1MQjLwbFkhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYLHXcy5c-Kj",
        "colab_type": "code",
        "outputId": "5781cb39-5a30-49b2-ba3e-d2f8ecfd168f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Needed to organize data for the classifier.\n",
        "# Only do ONE TIME for the training\n",
        "% cd /content/drive/My\\ Drive/polytech-ds-2019/polytech-ds-2019/training\n",
        "#! for i in `seq 0 10`; do mkdir class${i}; done\n",
        "#! for i in `seq 0 10`; do mv ${i}_* class$i; done\n",
        "! for i in `seq 0 10`; do ls -lh class${i}/ | wc -l; done"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/polytech-ds-2019/polytech-ds-2019/training\n",
            "995\n",
            "430\n",
            "1501\n",
            "987\n",
            "849\n",
            "1326\n",
            "441\n",
            "281\n",
            "856\n",
            "1501\n",
            "710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMeFALIwnSsJ",
        "colab_type": "code",
        "outputId": "41b06fcc-6722-4e6d-8594-29dbbe551dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Needed to organize data for the classifier.\n",
        "# Only do ONE TIME for the validation\n",
        "#! for i in `seq 0 10`; do mkdir ../validation/class${i}; done\n",
        "#! for i in `seq 0 10`; do mv ../validation/${i}_* ../validation/class$i; done\n",
        "! for i in `seq 0 10`; do ls -lh ../validation/class${i}/ | wc -l; done"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "365\n",
            "145\n",
            "502\n",
            "329\n",
            "327\n",
            "451\n",
            "148\n",
            "100\n",
            "348\n",
            "504\n",
            "233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzf27UOljeXe",
        "colab_type": "code",
        "outputId": "144d861f-3f02-457e-877d-e0f10d3b76ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load in each dataset and apply transformations using\n",
        "# the torchvision.datasets as datasets library\n",
        "% cd /content/drive/My\\ Drive/polytech-ds-2019/polytech-ds-2019/training\n",
        "data_set = datasets.ImageFolder(root=\"./\", transform = transformations)\n",
        "val_set = datasets.ImageFolder(root=\"../validation/\", transform = transformations)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/polytech-ds-2019/polytech-ds-2019/training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q48bSN1ZkEuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS86yQwgnCFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader = torch.utils.data.DataLoader(data_set, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF7qk-tB0ZmK",
        "colab_type": "code",
        "outputId": "ab5af8d3-88cb-43a8-a388-0e4b4effb1da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tensor, labels = next(iter(test_loader))\n",
        "tensor.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 224, 224])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpbDVQCFtadM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize image\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(data_loader))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "class_names = data_set.classes\n",
        "imshow(out, title=[class_names[x] for x in classes])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWTxUfWr0_Ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install --upgrade fastai"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeN8RxPR4gFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install --upgrade torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T72BnQFy68iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torchvision==0.1.9\n",
        "!pip install fastai\n",
        "!pip install torchtext==0.2.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6pP908x9wGy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIe_m35YzORo",
        "colab_type": "code",
        "outputId": "d2454a4b-bb65-44fd-f3f9-5af5ebf65a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from fastai.vision import *\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e1779a1ec7f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataBunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: from_df() missing 1 required positional argument: 'df'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbl1PddrEs1W",
        "colab_type": "code",
        "outputId": "d80d886f-aaa8-413c-d011-0e1fc8324f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: fastai: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWPuVs0p9Hxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}